{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_conclusion_remarks.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfZUlt2ZF28u",
        "colab_type": "text"
      },
      "source": [
        "# **0. Recap**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EMjT5WdwJVQe",
        "colab_type": "text"
      },
      "source": [
        ">The project was conducted by the following team members :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ow9IbN5LJC4x",
        "colab_type": "text"
      },
      "source": [
        "*   Besson, Dario – MLaw in Legal Issues, Crime and Security of IT (UNIL)\n",
        "*   Fleck, Alyssa – MLaw in Legal Issues, Crime and Security of IT (UNIL)\n",
        "*   Liao, Yi Chuan – Exchange Program (Taiwan)\n",
        "*   Nkoumondo, Laryssa – MLaw in Legal Issues, Crime and Security of IT (UNIL)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NmVIHI4wKJuG",
        "colab_type": "text"
      },
      "source": [
        ">All the notebooks are available here :"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DnxcY0mqKRbV",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "* `0_data_cleaning.ipynb` : The data needed to be cleaned in some aspects. Choices were made regarding which classes to keep for categorical features such as \"Facility Type\" for which more than 400 classes existed. Missing data was dealt with. Also, some features in the original data set were dropped.\n",
        "  * Link : [Data Cleaning](https://github.com/dbssn/DMML2019_Team_Microsoft/blob/master/code/0_data_cleaning.ipynb)\n",
        "* `1_augmentation.ipynb` : This file is the concretisation of the data augmentation possibilities which were presented above.\n",
        "  * Link : [Data Augmentation](https://github.com/dbssn/DMML2019_Team_Microsoft/blob/master/code/1_augmentation.ipynb)\n",
        "* `2_complementary_EDA.ipynb` : This file contains complementary exploratory data analysis which provides an insight on the data that will be used for this project. This includes map visualisation, histograms, etc.\n",
        "  * Link : [Complementary EDA](https://github.com/dbssn/DMML2019_Team_Microsoft/blob/master/code/2_complementary_EDA.ipynb)\n",
        "* `3_prediction.ipynb` : All the models tested are regrouped in this file. After normalising and encoding the data, several models were tested and assessed. This includes : decision tree, random forest, kNN, logistic regression.\n",
        "  * Link : [Prediction](https://github.com/dbssn/DMML2019_Team_Microsoft/blob/master/code/3_prediction.ipynb)\n",
        "* `4_conclusion_remarks.ipynb` : This notebook contains the conclusions and remarks for this project as well as the video and contributions from the team members.\n",
        "  * Link : [Conclusion & Remarks](https://github.com/dbssn/DMML2019_Team_Microsoft/blob/master/code/4_conclusion_remarks.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01MYcc0S_1vi",
        "colab_type": "text"
      },
      "source": [
        ">The video for this project is available right below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBW7k5M1MOeW",
        "colab_type": "code",
        "outputId": "20b1abe6-c5fc-4cc7-9526-7a702911fe69",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "%%HTML\n",
        "<video tabindex=\"0\" controls=\"\" preload=\"none\" style=\"max-width: 1024px; max-height: 1024px\">\n",
        "  <source src=\"https://drive.switch.ch/index.php/s/KpFDuSOqe0fAe8g/download\" type=\"video/mp4\">\n",
        "</video>"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<video tabindex=\"0\" controls=\"\" preload=\"none\" style=\"max-width: 1024px; max-height: 1024px\">\n",
              "  <source src=\"https://drive.switch.ch/index.php/s/KpFDuSOqe0fAe8g/download\" type=\"video/mp4\">\n",
              "</video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yv5H8IdTMsIB",
        "colab_type": "text"
      },
      "source": [
        "Link to the video if needed : https://drive.switch.ch/index.php/s/KpFDuSOqe0fAe8g"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZfLx_wTlFUH",
        "colab_type": "text"
      },
      "source": [
        "# **1. Business Understanding**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4pBEDF4a_1NF",
        "colab_type": "text"
      },
      "source": [
        "Hygiene in the food industry is essential to guarantee food safety. It is important for food inspections to be carried out efficiently, in a timely manner, in order to mitigate potential health risks that may exist. The main challenge lies in the ability of the government to detect food hazards rapidly.\n",
        "\n",
        "Data mining would help address this problem in the sense that it would allow large cities to find which establishments to target first. In addition, this project provides other business opportunities for companies interested in helping establishments pass the inspection. Moreover, establishments themselves could also benefit from this approach since they would gain knowledge on inspection failure drivers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZU6vyPRAUWq",
        "colab_type": "text"
      },
      "source": [
        "# **2. Data Understanding**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDTt6-xEAWxC",
        "colab_type": "text"
      },
      "source": [
        "The main datasets were found on the City of Chicago's data portal. The dataset gives us access to information on food establishments such as their legal or public name, licence number, facility type (bakery, coffee shop, etc.), address and risk category of facility (grouped into 3 risks according to the danger that it may exist to public health). This dataset also provides us with data about the inspection such as the inspection ID, date, type (canvas, consultation, complaint, license, suspect food poisoning or task force), violations and inspection result (pass or fail).\n",
        "\n",
        ">The sources are detailed in the data folder of the GitHub repository. Also, a detailed description of the augmented data set can be found in the `2_complementary_EDA.ipynb` notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1x2Ypn-Ad-D",
        "colab_type": "text"
      },
      "source": [
        "# **3. Data Preparation/Pre-processing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwnrzkjvAmxb",
        "colab_type": "text"
      },
      "source": [
        "The first step was to clean the data. This procedure is detailed int the ‘0_data_cleaning.ipynb’ notebook. The key elements were :\n",
        "* Only the “Fail” and “Pass” outcome were conserved, which is what defined this project as a binary classification. 52’229 rows were dropped.\n",
        "* NaN values were dropped too, 620 rows.\n",
        "* The “Facility Type” feature was cleaned by transforming it to lower case and by selecting the classes which had the highest count until 97.5% of the data set was covered.\n",
        "* The same procedure was applied for the “Inspection Type”, with a higher threshold of 99.7%.\n",
        "\n",
        "The next step was augmentation, which was performed in 3 ways. The first option was to use the information contained in the original data set to create new features. For example, the extraction of week day, month and year was extracted from the inspection date. The length of the comment in the “Violations” field was added under the assumption that the longer the text, the more violations there are.\n",
        "\n",
        "The second option was to use the NOAA Weather history for Chicago. This set was used to retrieve the maximum daily temperature and the average maximum temperature of the last 3 days for a given date of inspection.\n",
        "\n",
        "The last option consisted using the Business Licenses dataset to obtain the approximate date of creation for the establishments.\n",
        "\n",
        ">These 3 procedures are detailed in a notebook called ‘1_augmentation.ipynb’.\n",
        "\n",
        "After augmenting the data set, continuous variables were standardised, and categorical variables were one-hot encoded. Before selecting the models, principal component analysis and a random forest model were used to lower the dimensionality, which would make the algorithms training and fine-tuning faster.\n",
        "\n",
        ">This was done in the ‘3_prediction.ipynb’ notebook.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yO5QNXPUAooy",
        "colab_type": "text"
      },
      "source": [
        "# **4. Data Mining/ML Algorithms used and why**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7S3aL1caArTD",
        "colab_type": "text"
      },
      "source": [
        "First, we tried as much as algorithms we could. We evaluated the performances and chose the best 3 algorithms to do the grid search for hyper parameters. Then, we put them into a voting ensemble.\n",
        "\n",
        "MLPClassifier is a kind of fully connected neural network. It uses activation =  ”relu” that can solve non-linear problem. For this reason, it is able to simulate any kind of function. However, it also requires many try and error on layer sizes and layer length.\n",
        "\n",
        "Gradient Boosting is a method of converting weak predictors into strong predictors. For boosting, each new decision tree would be fit on a different slice of the original dataset. Gradient Boosting trains many models in a gradual and additive manner. It uses gradients in the loss function to indicate how good the model’s coefficients are.\n",
        "\n",
        "Xgboost is just a special version of Gradient Boosting. It adopts a more regularized model formalization to control overfitting issues. On the other hand, it focuses on the computational speed of model which also makes it becomes a popular algorithm nowadays.\n",
        "\n",
        "Voting is an ensemble method that combines different predictors to enhance performances. In our case, the 3 models above are combined into a “hard” vote system."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2JTnn6kjAuuT",
        "colab_type": "text"
      },
      "source": [
        "# **5. Evaluation/Graphs/Tables**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "epcL10nEAxHi",
        "colab_type": "text"
      },
      "source": [
        "The voting ensemble achieved a 0.8 accuracy. It was trained on a balanced data set, X_train, (downsampled the majority class) and tested on an unbalanced data set, X_test. The initial base rate was 75.4%, but after downsampling, it decreased to 50%. Those are the results :\n",
        "* Accuracy : 0.8\n",
        "* F1 Score : 0.858\n",
        "* Recall : 0.804\n",
        "* Precision : 0.92\n",
        "\n",
        "The most important features were found with the XGB classifier. In decreasing order, those are :\n",
        "* `LenViol` : While this feature is a strong predictor, this information is obtained after the inspection and this is a limitation.\n",
        "* `license` : Businesses that pass their first inspection are more likely to fail. From a business opportunity perspective, those are the potential customers that should be targeted.\n",
        "* `canvass re-inspection` : It seems that routine re-inspection are also a predictor.\n",
        "* `DaysInBusiness` : The “age” of the business is a predictor. Young businesses are more likely to fail.\n",
        "* `Risk 1 (high)` : Establishments classified as high risk face more frequent inspections. Again, those are potential customers for companies in the food inspection business.\n",
        "* `complaint re-inspection` : Repetitive complaints is also a predictor. Restaurants with repetitive complaints should be targeted first.\n",
        "* `complaint` : When a complaint triggers an inspection, the establishment is more likely to fail.\n",
        "* `license re-inspection` : When businesses have to renew their licenses, the re-inspection can fail.\n",
        "* `Risk 3 (low)` : Low risks establishments could be less prepared for inspections since they are less frequent. \n",
        "* `license task-force` : Bar and taverns inspections have a higher fail rate, which make them potential clients too.\n",
        "\n",
        ">Business opportunity : The implications of failing the inspection can be harmful in terms of reputation, clientele, revenues for restaurants. This could lead them to seek help when facing an inspection. The model could help businesses offering services in the food inspection segment to identify which establishments to target in their marketing campaign. The ROI cannot be calculated because it is not possible to assess how much more accurate the campaign would be.\n",
        "\n",
        ">Government :  The model should help the city target the restaurants that are likely to fail in a more efficient way, such that public health and safety are guaranteed. In this way, the fail rate for inspection may be a possible evaluation target. That is to say, the government actually could detect more problematic restaurants constrained on limited personnel.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cOT-D79CA1Qj",
        "colab_type": "text"
      },
      "source": [
        "# **6. Deployment**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TKaS2ngA34S",
        "colab_type": "text"
      },
      "source": [
        "This project was possible because the data is open source. The USA have a different approach to privacy and such a data set is not likely to be published in Europe. As long as the US position does not change, the deployment of such projects is feasible. Should the data be retained by the state, gathering such a data set would be impossible.\n",
        "\n",
        ">Challenges :\n",
        "One thing that was very challenging was how to deal with re-inspections. One restaurant could fail/pass the inspection at a different point in time, but its characteristics are stable over time. We had to find a way to use temporal data in a way that it would differentiate the same restaurant from itself. This was achieved by computing the “DaysInBusiness” feature.\n",
        "\n",
        ">Limitations :\n",
        "We would have liked to gather more information about the establishments to better discriminate them from one another. We thought about using an API, but due to time and technical constraints, we did not implement it. This could be done in future work.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6YLZSq_A6Ea",
        "colab_type": "text"
      },
      "source": [
        "# **7. Contributions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeUAOk1iA7-r",
        "colab_type": "text"
      },
      "source": [
        "* **Besson D.** : Participation in discussion and group meetings, data collection, data cleaning, data augmentation, EDA, pre-processing, readme, notebook writing and formatting, video and presentation.\n",
        "* **Fleck A.**: Participation in group meetings and project ideas, data testing, participation in notebook writing and presentation\n",
        "* **Liao Y. C.** :  Participation in discussion and group meetings, models creation, prediction, notebook writing and presentation.\n",
        "* **Nkoumondo L.** : Participation in discussion and group meetings, proposal of a data set for augmentation, proposal of an algorithm for data cleaning."
      ]
    }
  ]
}